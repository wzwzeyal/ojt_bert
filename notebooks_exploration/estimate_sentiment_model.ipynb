{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Estimate Sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the bert model reop\n",
        "1. Contains the model\n",
        "2. Containg the model trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5omCl7qi51D",
        "outputId": "f09d1c5d-a99b-486c-c48c-b2e992e383ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'bert_classifier_repo' already exists and is not an empty directory.\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pjsSVpOpbCk7ce8ZppbEqk8DjGK4q1Sf\n",
            "To: /content/bert_token.pt\n",
            "100% 438M/438M [00:05<00:00, 81.4MB/s]\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.15.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "fatal: destination path 'ojt_bert' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/wzwzeyal/bert_classifier_repo.git\n",
        "!gdown --id 1pjsSVpOpbCk7ce8ZppbEqk8DjGK4q1Sf\n",
        "!pip install transformers\n",
        "!git clone https://github.com/wzwzeyal/ojt_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "IEC8cYnUi51H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from bert_classifier_repo.module import BertClassifierModule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The sentiment would be prediceted using\n",
        "1. finetuned bert model\n",
        "2. pretrained bert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ING1J5vgHyO0"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## finetuned bert model\n",
        "\n",
        "The model was fintuned in colab gpu using the notebook\n",
        "*finetune_bert_gpu.ipynb*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY-0Bpssi51I",
        "outputId": "cfc1e696-3a2f-4382-fae7-2d4987dc6a9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at avichr/heBERT_sentiment_analysis were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_model_name = 'avichr/heBERT_sentiment_analysis'\n",
        "\n",
        "state_dict = torch.load('bert_token.pt', map_location=device)\n",
        "\n",
        "model = BertClassifierModule(bert_model_name)\n",
        "\n",
        "model.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "uT36-nbui51K"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(bert_model_name)\n",
        "max_len = 130"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "piHg4IQ2i51K"
      },
      "outputs": [],
      "source": [
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=sent,#text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length= max_len,                  # Max length to truncate/pad\n",
        "            #  The `pad_to_max_length` argument is deprecated and will be removed in a future version, \n",
        "            # use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, \n",
        "            # or use `padding='max_length'` to pad to a max length. \n",
        "            # In this case, you can give a specific length with `max_length` \n",
        "            # (e.g. `max_length=45`) or leave max_length to None to \n",
        "            # pad to the maximal input size of the model (e.g. 512 for Bert).\n",
        "\n",
        "            # pad_to_max_length=True,         # Pad sentence to max length\n",
        "            padding='max_length',\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "7lRBc4Pii51M"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = 'ojt_bert/data/for_sentiment'\n",
        "\n",
        "X_val = pd.read_csv(f'{ROOT_PATH}/val_token_df.gz')\n",
        "\n",
        "val_inputs, val_masks = preprocessing_for_bert(list(X_val.comment_clean.values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "7lpIPxpKHaSF"
      },
      "outputs": [],
      "source": [
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "t1Kt7mScGmeE"
      },
      "outputs": [],
      "source": [
        "def predict(comments):\n",
        "  with torch.no_grad():\n",
        "    val_inputs, val_masks = preprocessing_for_bert(comments)\n",
        "    val_inputs = val_inputs.to(device)\n",
        "    val_masks = val_masks.to(device)\n",
        "    model.eval()\n",
        "    outputs = model(val_inputs, val_masks)\n",
        "    results = torch.argmax(outputs, dim=1)\n",
        "    return results.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "GRWo7evTJwgF"
      },
      "outputs": [],
      "source": [
        "X_val['finetune'] = predict(X_val.comment_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Jv9aWtoHJwdE",
        "outputId": "23f644ef-8490-4d6b-a4af-77fdcaf42cf6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2e44c76b-7f76-4da9-92be-71e14517bc7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "      <th>comment_clean</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>comment_clean_len</th>\n",
              "      <th>finetune</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>מתבייש בך שאתה הנשיא שלי . חשבתי שיש בך קצת יו...</td>\n",
              "      <td>1</td>\n",
              "      <td>מתבייש בך שאתה הנשיא שלי חשבתי שיש בך קצת יותר...</td>\n",
              "      <td>neg</td>\n",
              "      <td>72</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>מזל טוב לעם ישראל שהנשיא העשירי שנבחר הוא ראוב...</td>\n",
              "      <td>0</td>\n",
              "      <td>מזל טוב לעם ישראל שהנשיא העשירי שנבחר הוא ראוב...</td>\n",
              "      <td>pos</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>מקסים 😊</td>\n",
              "      <td>0</td>\n",
              "      <td>מקסים</td>\n",
              "      <td>pos</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>דניאל כך הכבוד</td>\n",
              "      <td>2</td>\n",
              "      <td>דניאל כך הכבוד</td>\n",
              "      <td>nut</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>אחלה נשיא רובי ....</td>\n",
              "      <td>0</td>\n",
              "      <td>אחלה נשיא רובי</td>\n",
              "      <td>pos</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e44c76b-7f76-4da9-92be-71e14517bc7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e44c76b-7f76-4da9-92be-71e14517bc7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e44c76b-7f76-4da9-92be-71e14517bc7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ... finetune\n",
              "0           0  ...        1\n",
              "1           1  ...        0\n",
              "2           2  ...        0\n",
              "3           4  ...        0\n",
              "4           5  ...        0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_val.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## pretrained bert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfWRhibWL5Ct",
        "outputId": "0fe163b3-d8df-4dcc-b472-f09e6765317c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at avichr/heBERT_sentiment_analysis were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"avichr/heBERT_sentiment_analysis\") #same as 'avichr/heBERT' tokenizer\n",
        "model = AutoModel.from_pretrained(\"avichr/heBERT_sentiment_analysis\")\n",
        "\n",
        "# how to use?\n",
        "sentiment_analysis = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=\"avichr/heBERT_sentiment_analysis\",\n",
        "    tokenizer=\"avichr/heBERT_sentiment_analysis\",\n",
        "    return_all_scores = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "RTcp4Uu3L482"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(sentiment_analysis(list(X_val.comment_clean)))\n",
        "codes = {'positive' : 0, 'negative': 1, 'neutral' : 2}\n",
        "X_val['pretrain'] = df['label'].map(codes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finetuned and pretrained comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "5iNSwFV_WPvz",
        "outputId": "d6359d36-3da7-43a5-bff6-59e3e0194ee4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f01b95aa690>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1440x576 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.set(rc={'figure.figsize':(20,8)})\n",
        "\n",
        "fig, axs = plt.subplots(1,2)\n",
        "\n",
        "axs[0].set_title('pretrain')\n",
        "sns.heatmap(confusion_matrix(X_val.label, X_val.pretrain), annot=True, ax=axs[0], fmt='g')\n",
        "\n",
        "axs[1].set_title('finetune')\n",
        "sns.heatmap(confusion_matrix(X_val.label, X_val.finetune), annot=True, ax=axs[1], fmt='g')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at onlplab/alephbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(52000, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertModel, BertTokenizerFast\n",
        "\n",
        "alephbert_tokenizer = BertTokenizerFast.from_pretrained('onlplab/alephbert-base')\n",
        "alephbert = BertModel.from_pretrained('onlplab/alephbert-base')\n",
        "\n",
        "# if not finetuning - disable dropout\n",
        "alephbert.eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "estimate_sentiment_model.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "d4a6d3944a949846f4664787b256241dcb769797b6827641bf384da575c62243"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
